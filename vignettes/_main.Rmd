---
title: "Introduction"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "6 Juli 2016"
output: html_document
---

visCOS is still under (heavy) development, so it is not recommended to use the
package, yet. If you want to do it nevertheless...

visCOS is an R-package that provides summaries and visualisation to support
parameter estimation for conceptual rainfall-runoff models in general and
COSERO in special. COSERO is a hbv-like model that was developed at the
institue for water management, hydrology and hydraulic engineering (IWHW) at
BOKU, Vienna. The name is an abreviation for "**Co**nceptual
**Se**mi-Distributed **R**ainfall Run**o**ff Model".
This page provides a hub to access the differnet examples and the entire program
code.

# Table of Content
**1. Basics** 

- [The basic data structure](LP-cookd_data.html)
- [Set Options](LP-viscos_options.html)

**2. Data Cooking**

- [Time aggregation](LP-aggregationsplots.html)
- [Objective Functions](LP-main_of.html)
- [Explore Runoff and Objective Functions](LP-explore_runoff.html)

**3. Plotlists**

- [Objective Function Plots](LP-plot_main_of.html)
- [Saving Plots](LP-serve.html)

**Other**

- [Defensive Code](LP-defensive_code.html)
- [Helper Funcitons](LP-helpers.html)


<!--chapter:end:Introduction.Rmd-->

---
title: "Cooking Data"
author: 
- "Daniel Klotz, Johannes Wesemann"
date: "6 Juli 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE, fig.align = 'center')
```

# Introduction
This section defines code of the **visCOS** functions used for "cooking data".
Within the scope of **visCOS** "cooking data" is defined as the process of
transforming *raw data* into *cooked*, which can be used for the internal
visualisations.

# Examples
In this chapter examples for **visCOS**-functions are given that deal with the 
process of transforming  *raw data* into prepared data for **visCOS**.
The data is then *cooked* and can be used for figures etc.

The following steps can be performed:

* Loading of raw data (always necessary if data is not loaded yet)
* Setting visCOS_options (if it doesn't fit your data)
* Remove junk and prepare date format 
* Define and Mark periods

## Loading raw data
From the point of view of **visCOS** raw-data are time-series of observations
and model output. Usually raw data is saved in some simple file format,
e.g. *.txt* or *.csv*. `R` already includes many option to read those files
with the `read.table` functionalities.
For larger unstructured files the read options of the `data.table` package is 
recommended. In our tests it was fastest and most flexible option.
Alternatively the `readr` can be used if the data is more structured and large.

**Note** at this stage, only a comparison between **numbered catchments** 
 for two parameters is possible. So the data must include an integer 
number after the description (like "QObs_001" and "QSim_001").

The function `get_runoff_example` can be used to get some exemplary data
from within **visCOS**:
```{r, purl=FALSE, eval=TRUE, message=3:5}
  library(visCOS)
  require(magrittr)
  options(width=80)
  runoff_example_raw <- get_runoff_example()
  head(runoff_example_raw)
```

## Prepare the raw data
### Adapt `viscos_options`
The next step would be to adapt the first part of the `viscos_options`. This 
can be done by copying the default settings from the help and adapt them. In 
this case they are already correct:
```{r, purl=FALSE, eval=TRUE}
   viscos_options(
   # data.frame column names
      name_o = "qobs",
      name_s = "qsim",
      name_COSyear = "yyyy",
      name_COSmonth = "mm",
      name_COSday = "dd",
      name_COShour = "hh",
      name_COSmin = "min",
      name_COSposix = "posixdate",
      name_COSperiod = "period")
```

### Remove junk and prepare date format
Now all the junk data (data columns not needed, unobserved basins) can be 
removed using the `remove_junk` function. Additionally, leading zeros in the 
column names can be deleted with `remove_leading_zeros` if necessary.

In order to properly analyse the data with **visCOS**, the timesteps must be 
complete and in the right format. This can be done with `prepare_complete_date`. 
Within the data.frame the user has to provide either 5 columns with the 
*COSdate* format: `yyyy-mm-dd-hh-min` i.e.: year-month-day-hour-minute or an 
equivalent column in `POSIXct` format (see: [link](https://stat.ethz.ch/R-manual/R-devel/library/base/html/as.POSIXlt.html))
 to do so.
```{r, purl=FALSE, eval=TRUE}
  runoff_example <- remove_junk(runoff_example_raw) %>% 
  prepare_complete_date()
head(runoff_example)
```

### Define and Mark periods
If a seasonal or periodical analysis of the data wants to be done, these periods 
can be defined with the `mark_periods` function. In the example case, the 
hydrological years, going from September till August, will be defined:
```{r, purl=FALSE, eval=TRUE}
  runoff_example <- mark_periods(runoff_example, start_month = 9, end_month = 8)
# here is an example plot to visualise the periods
  plot(runoff_example$period, xlab="Timestep", ylab="# of hydrological year")
```

Note that the example data starts with beginning of September, so right with 
the first hydrological year. The end of the year 2010 is not completely inside 
a hydrological year, so the period counter jumps to one.

# Code
The following functions are defined below. Exported functions can be seen by the
user.

## `get_runoff_example`
visCOS porvides some exemplary data. All the available functions can be tested
with it. `get_runoff_example` is a small wrapper function to get the data from
within the package via `read.csv`

**Note** at this stage, only a comparison between **numbered catchments** 
is possible for two parameters is possible. So the data must include an integer 
number after the description (like "QObs_001" and "QSim_001")
```{r, echo=FALSE}
  #' Get runoff example
  #'
  #' Get exemplary runoff data to test the different functions of visCOS
  #' @export
  
```

```{r}
  get_runoff_example <- function() {
    file_path <- system.file("extdata",
                             "runoff_example.csv",
                             package = "visCOS")
    runoff_example <- read.csv(file_path)
    return(runoff_example)
  }
```


## `remove_junk`
This function removes all columns not specified in the `viscos_options`,
as well basins where no observations are available.
The first part is done by identifying the names of the data_frame and
searching for the idx of the names defined in the `viscos_options`.
The second part is done via the function `prepare.only_observed` (see next 
subchapter). It is actually so pretty simple, but really useful. Since the 
solution is quite specific, the function tests if the input is a data.frame and 
returns an error if not.

**Note** that the routine is **not** case sensitive. It does not distinguish
between small and capital letters!

```{r echo=FALSE}
  #' removes chunk in runoff_data
  #'
  #' Removes all columns which are not foreseen (see: viscos_options) from
  #' runoff data
  #'
  #' @param runoff_data data.frame object containing at least COSdate,
  #' and two data rows defined in viscos_options
  #' @return data.frame object without the chunk
  #' 
  #' @import magrittr
  #' 
  #' @export

```

The first part of the code loads the dependencies and makes sure that the
runoff_data variable is a data.frame (see: chapter about *defensive coding*):
```{r}
  remove_junk <- function(runoff_data) {
```

The body of `remove_junk` works as following: First, the names of the columns 
of the runoff_data are determined via `names` and all set to lower letters with
`tolower`. This is the reason why the function is not case sensitive!
Then helper function `get_regex_for_runoff_data` is called to get regular
expressions that identify the wanted columns. Later, `grep` is used to get
the index `idx` of the columns with the given names (`lowercase_names_in_data`).
Finally, `idx`is then used to select the wanted columns.

In the second part, the function `only_observed_basins` is being executed (see 
next chapter)
```{r}
  assert_dataframe(runoff_data)
  # 
  lowercase_names_in_data <- runoff_data %>% names %>% tolower
  regex_columns <- get_regex_for_runoff_data() %>% tolower # see: helpers
  # 
  idx <- regex_columns %>%
    grep(.,lowercase_names_in_data)
  no_chunk_runoff_data <- runoff_data[ , idx]
  return( only_observed_basins(no_chunk_runoff_data) )
  }
```


### `only_observed_basins`
This function removes basins for which no observations are available. No
observation are interpreted as columns in which all the entries are either -999
or `NA's`. 
```{r, echo=FALSE}
  # remove basins without observations
  #
  # Removes basins without observation (-999/NA values) from the provided data.frame
  #
  # @param runoff_data A raw runoff_data data.frame, which may contains basins
  # without observations.
  # \strong{Note:} It is assumed that all available basins are simulated!
  # @return data.frame without the observation-free basins
  # 
  # @import magrittr
```

Initiation of function: 
```{r}
only_observed_basins <- function(runoff_data) {
  require("magrittr")
  assert_dataframe(runoff_data)
```

In order to handle the `NA's` and -999 in the same way all `NA's` are replaced
with -999. Then the `lapply` function is used to find the max of each column.
```{r}
  chosen_cols <- which( names(runoff_data) != viscos_options("name_COSposix") )
  chosen_rows <- is.na(runoff_data[,chosen_cols])
  data_no_posix <- runoff_data[ ,chosen_cols]
  data_no_posix[chosen_rows] <- -999
  colmax <- lapply(X = data_no_posix, FUN = max) # get max of any column
```

If any column has a max of -999 it is worth further investigation.
Unfortunately the -999 columns could also mean, that something went wrong
with the simulation, thus one has to make sure that only observation columns
are selected. To do so we first identify the idx of the max == -999 cols and
build a regular expression with the help of the `viscos_options`.
We combine both information via `grepl` to check if only observed columns have
been selected. If so everything is fine, but if `any` of the selected cols came
from an simulation col the function stops the execution and gives a warning
message.
The next step involves a little trick in which +1 is added to the `idx` to
obtain the indexes of the corresponding simulation. Here we assume that for each
observation there is a corresponding simulation **in next the next colum**!
This allows us then to select only the observed basins. But now all NA values
are actually -999! Thus, we replace them again back to NA, via `lapply(...,min)`
assuming that all negative values are NAs. This is not a strong assumption,
because there should never be negative flows! In the end the resulting
data.frame is returned.
```{r}
  if ( any(colmax < 0.0) ){
    idx_temp <- which(colmax < 0.0)
    obs_regex <- paste(viscos_options("name_o"),".*", sep ="")
    OnlyQobsSelected <- idx_temp %>%
      names %>%
      tolower %>%
      grepl(obs_regex,.) %>%
      any
    if (!OnlyQobsSelected){
      stop("There are Qsim withouth simulation (i.e. only values smaller 0). Pls remove them first")
    }
    idx_slct <- c(idx_temp,idx_temp + 1) %>% sort()
    d_onlyObserved <- runoff_data[-idx_slct]
    # set remaining negative Qobs to NA, so that HydroGOF can be used correctly, also ignoring NAs
    colmin <- lapply(X = d_onlyObserved, FUN = min)
    idx_temp <- which(colmin < 0.0)
    d_onlyObserved[d_onlyObserved[idx_temp]<0, idx_temp] <- NA
    return(d_onlyObserved)
  } else {
    return(runoff_data)
  }
}


```


## `prepare_complete_date`
This function is a wrapper. It is however not finished yet!
The idea is the following. The idea is to provide a handy function to complete
the date-columns. Within the data.frame the user has to provide either 5 columns
with the *COSdate* format: `yyyy-mm-dd-hh-min` i.e.: year-month-day-hour-minute or
an equivalent column in `POSIXct` format
(see: [link](https://stat.ethz.ch/R-manual/R-devel/library/base/html/as.POSIXlt.html)).

*However*, it is currently only possible to convert *COSdate* into `POSIXct` dates
via the `implode_cosdate` function.

The function itself is basically a switch which calls different functions
if `name_cosyear` and/or `name_posix` is found and returns an error if none of
the two are found. If the user has not named his columns according to COSERO
convention he can provide the names of the *COSdate* year via `name_cosyear` and
the names of the POIXct column via `name_posix` within the `viscos_options`. The function returns an error
if `runoff_data` is not a data frame and if `OK_COSdate` or `OK_POSIXdates` are
not logical due to some problems with the dates/time-formats.

A *caveat* with this method is that only the `name_cosyear` is checked to infer
if the 5 *COSdate* columns are available. This can cause errors later if some
other columns are missing. Sadly it is not apparent how to avoid that problem,
without defining the names of all columns.

Furthermore, we need to be aware that with *UTC* a fixed time-zone is
assumed to avoid problems with leaps in time (summer/winter time).

The function `implode_cosdate` is used to obtain the POSIXct date from the
*COSdate* columns. The following chapter will show how this is done.
```{r}
  #' Complete the date-formats with POSIXct or COSdate
  #'
  #' Complete the data-formats of your data.frame `POSIXct` and/or `COSdate`
  #'
  #' @param runoff_data The data.frame, which contains the runoff information
  #' @param name_cosyear string with the name of the `COSdate` year column
  #' @param name_posix string with the name of the POSIXct column
  #' @return The new runoff data.frame with the added data-format.
  #' 
  #' @import magrittr
  #' 
  #' @export
prepare_complete_date <- function(runoff_data = NULL,
                                  name_cosyear = "yyyy",
                                  name_posix = "POSIXdate") {
  # make sure that magrittr is loaded:
  assert_dataframe(runoff_data)
  # check for COSdates and stop if non-logical expression are obtained
  OK_COSdate <- any(names(runoff_data)== viscos_options("name_COSyear"))
  OK_POSIXdates <- any(names(runoff_data)== viscos_options("name_COSposix"))
  if ( !is.logical(OK_COSdate) | !is.logical(OK_POSIXdates) ) {
    stop("Something seems to be wrong with the date / time formats :(")
  }
  # choose function depending on which formats are available!
  if (!OK_COSdate & !OK_POSIXdates) {
    stop("No COSdates and no POSIXct-dates in the data!")
  } else if (OK_COSdate & !OK_POSIXdates) {
    runoff_data <- implode_cosdate(runoff_data) # see following chapter
  } else if (!OK_COSdate & OK_POSIXdates) {
    stop("POSIXct to COSdates not yet supported :(")
  }
  return(runoff_data)
}
```

### `implode_cosdate`
This function is used to transform the old-school *COSdate* format into the
widely spread POSIXct format, used within R and in many packages. The function
is called by the function above and not provided to the user! It takes a
data frame (`runoff_data`) and uses `viscos_options` to transform the different
*COSdate* columns into POSIXct dates via `paste`.
```{r, echo=FALSE}
# transform COSdate into the nicer POSIXct-date format
#
# Takes a data.frame, which contains the COSdate format (see: xxx) and
# transforms it into a POSIXct series. Note that time is assumed to be in UTC
```
The paste function is used to concatenate the different *COSdate*
columns (i.e. year, month, day, hour and minute) to a POSIXct date format.
The obtained series of strings is saved into the variable `POSIXdate` and
added as the column `viscos_options("name_COSposix")` (see section about
`viscos_options`) to the `runoff_data.
```{r}
implode_cosdate <- function(runoff_data) {
  require("magrittr", quietly = TRUE)
  assert_dataframe(runoff_data)
  name_string <-  runoff_data %>% names %>% tolower
  #
  POSIXdate <- paste(runoff_data[[viscos_options("name_COSyear")]],
                     sprintf("%02d",runoff_data[[viscos_options("name_COSmonth")]]),
                     sprintf("%02d",runoff_data[[viscos_options("name_COSday")]]),
                     sprintf("%02d",runoff_data[[viscos_options("name_COShour")]]),
                     sprintf("%02d",runoff_data[[viscos_options("name_COSmin")]]),
                     sep= "" ) %>%
    as.POSIXct(format = "%Y%m%d%H%M", origin = .[1], scale = "hourly", tz = "UTC")
  runoff_data[[viscos_options("name_COSposix")]] <- POSIXdate
  return(runoff_data)
}
```


## `remove_leading_zeros`
This function removes leading zeros from column names of the data.frame
`runoff_data`.The function has no defensive coding, apart from the execution
of `remove_junk` (see corresponding chapter) to be sure that no non-needed
columns are within the data.frame.

```{r}
# remove leading zeros from the names of runoff_data (data.frame)
remove_leading_zeros <- function(runoff_data) {
  require("magrittr", quietly = TRUE)
  runoff_data %<>% remove_junk
```

The body of the function works in the following way:
The variables `runoff_names` is computed by obtaining the names of the columns
of `runoff_data` with `names` and removing all the digits with
`gsub("\\d",...)`. The basin digits, `runoff_nums` are computed by doing the
oposite, i.e.: removing all the non digits via `gsub("\\D",...)`. Afterwards,
the empty strings ("") are replaced with a small trick: The characters are
transformed into a numerics (induces `NA's`) and back again.
In the last step the variables `runoff_names` and `runoff_nums` are simply put
togehter again via the paste command. The result has no leading zeros as in the
variable numeration.
```{r}
  runoff_names <- runoff_data %>% names
  runoff_lowercase_names <- runoff_names %>% tolower 
  #
  separator <- runoff_lowercase_names %>% 
    extract( grep(viscos_options()$name_o,.) ) %>% 
    extract( 1 ) %>%
    gsub(viscos_options()$name_o,"",.) %>% 
    gsub("\\d","",.)
  searchterm <- paste0(viscos_options()$name_o,"|", viscos_options()$name_s)
  runoff_nums <- runoff_lowercase_names %>% 
    gsub(searchterm,"",.) %>% 
    gsub(separator,"",.) %>% 
    gsub("\\D","",.)
  searchterm <- paste(runoff_nums, collapse = "")
  runoff_only_names <- runoff_names %>% 
    gsub(paste0("[",searchterm,"]"),"",.) %>% 
    gsub(separator,"",.)
  runoff_new_numbers <- runoff_nums %>% as.numeric() %>% as.character()
  runoff_new_numbers[is.na(runoff_new_numbers)] <- ""
  #
  names(runoff_data) <- runoff_new_numbers %>% 
    gsub("\\d+",separator,.) %>% 
    paste0(runoff_only_names,.,runoff_new_numbers)
  return(runoff_data)
}
```


## `mark_periods`
This function can be used to create a periods column in your data.frame. The
period column is an integer vector, which is a multiple of 1 if the row is 
within a certain period and 0 if it is out of the period.

Building it was actually quite tricky. The author himself (Klotz) is not
sure if it is really a nice solution. But it is the best solution, in terms of
speed and clearness, that we could come up so far. So take it as a challenge
to build a better solution!

As shown below the function takes the `runoff_data` data.frame and the two
integers `start_month`and `end_month`. They allow the user to define the periods
within the `runoff_data` on a monthly resolution. As the name suggests
`start_month` defines the beginning of the period and `end_month` the end of
the period. The function requires `dplyr` and `magrittr` and tests if
`runoff_data` is a data.frame. An error is returned if it is not.
Furthermore, if there is *chunk* in the data.frame it is removed by
`remove_junk` and `prepare_complete_date` (see above)is used to ensure that
the full time-information, i.e. both date formats, is available.
```{r, echo=FALSE}
  #' calculate periods
  #'
  #' Mark the periods within runoff_data.
  # The marking uses a monthly resolution, which are defined by the integers
  #' `start_month` and `end_month`.  
  #'
  #' @param runoff_data The data.frame, which contains the runoff information
  #' @return The runoff data.frame reduced and ordered according to the
  #' hydrological years within the data.
  #' \strong{Note:} The periods columns are formatted as characters!
  #' 
  #' @import dplyr
  #' @import magrittr
  #'
  #' @export
```

```{r}
mark_periods <- function(runoff_data, start_month = 10, end_month = 9) {
  assert_dataframe(runoff_data)
  runoff_data %<>% remove_junk %>% prepare_complete_date()

```


The body of the function is split in two parts.
In the *first part* the variable `period_range` is defined as a integer sequence
from the `start_month` to the `end_month`.
The solution distinguishes between two different cases:
`start_month` <= `end_month` and `start_month` > `end_month`. The solution
for the former is trivial, as `seq` can be used. In principle the solution for 
the latter is also simple as two ranges (`range_1` and `range_2`) can be
constructed and concatenated. Note that both solutions additionally construct 
the integer-vector `out_of_period`. The vector contains information about the 
months which are not within the period_range. It would not be necessary for this 
case. But, since the current solution still seems to be suboptimal, it is 
needed for the second case, in order to mark the months which are out of the 
period later.
```{r}
  # (I) get labels for the months
  if (start_month <= end_month ) {
    period_range <- seq(start_month,end_month)
    out_of_period <- seq(1,12) %>% extract( !(seq(1,12) %in% period_range) )
  } else if (start_month > end_month) {
    range_1 <- seq(start_month,12)
    range_2 <- seq(1,end_month)
    period_range <- c(range_1,range_2)
    out_of_period <- seq(1,12) %>% extract( !(seq(1,12) %in% period_range) )
  }
```

The *second part* is a bit trickier.

First, the function `eval_diff` is defined. It takes a vector `a` and 
calculates the differences for it, where the first entry of `a` is kept,
e.g. `eval_diff( c(3,2,5,7,8) )` is `3 -1  3  2  1`.
Then, `eval_diff` is used to to mark all the starting months of the runoff data 
and saves them into a `period` column. The `pmax(.,0)` operation guarantees that
negative differencing (as above in 3 -> 2) is not included and the cumulative
sum is used to count the periods are within the data.frame. Therefore, at the 
beginning of the first period, the counter jumps to "1" and becomes "2" with the 
beginning of the second period and so on. 

Secondly, the `out_of_period` of all years is set back to zero again by simply
checking which months of our data.frame are equal to the `out_of_period` entries.
There are two problems with that solution. One is that the last year is not
extracted properly if `start_month` > `end_month`. For this case `dplyr::mutate`
is used to set the out-of-period-dates from the last year to 0, if they are 
bigger then `end_month`.
The second problem is that the first and last period are also included in the
solution even if they are **not** complete! *Thus, if a user does not want 
these solutions to be "marked" he has to remove it himself!*
```{r}
  # (II) mark periods:
    eval_diff <- function(a) {c(a[1],diff(a))}
    runoff_data[[viscos_options("name_COSperiod")]] <- 
      runoff_data[[viscos_options("name_COSmonth")]] %in% c(start_month) %>%
      eval_diff %>%
      pmax(.,0) %>%
      cumsum
    runoff_data$period[runoff_data[[viscos_options("name_COSmonth")]] %in% out_of_period] <- 0
    # corrections for last year
    max_year <- max(runoff_data[[viscos_options("name_COSyear")]])
    runoff_data %<>% dplyr::mutate(
      period = ifelse(
        (  (.[[viscos_options("name_COSyear")]] == max_year) &
           (.[[viscos_options("name_COSmonth")]] > end_month)  ),
                      0,
                      period
        )
      )
    return(runoff_data)
}
```

Here are two example plots to display the periods numbering:
```{r, eval=TRUE, purl=FALSE}
require(magrittr)
require(visCOS)
# mark_periods example 1: Hydrological years (September till August)
# note that the last year is not complete, so the counter jumps back to 0
ex1 <- get_runoff_example() %>% mark_periods(.,start_month = 9, end_month = 8)
plot(ex1$period, xlab="Timestep", ylab="# of hydrological year")

# mark_periods example 2: Summer Months (June till August)
ex2 <- get_runoff_example() %>% mark_periods(.,start_month = 6, end_month = 8)
plot(ex2$period, xlab="Timestep", ylab="# year of summer months")

```


## `runoff_as_xts`
This function is actually just a small wrapper around the `xts::xts` function 
for the purposes of **visCOS**. `runoff_as_xts` depends on `magrittr`, `xts` and
`zoo` (where the last one is acutally a dependency of `xts`).
The function takes the runoff_data as input and makes sure that the data is a
data.frame (check: `assert_dataframe` in the **defensive code** chapter),
has no "junk" inside (`assert_chunk`, see also: `remove_junk`) and
has all the needed date/time columns (`assert_complete_date`, see also:
`prepare_complete_date`).
```{r, echo=FALSE}
  #' Convert runoff_data to xts-format
  #'
  #' Converts the runoff_data (class: data_frame) into an xts object
  #'
  #' @param runoff_data data_frame of the runoff_data (see: xxx)
  #' @return xts object of the runoff_data data.frame
  #' 
  #' @import zoo 
  #' @importFrom xts xts
  #' @import magrittr
  #' 
  #' @export
```
```{r}
runoff_as_xts <- function(runoff_data) {
  # pre
  assert_dataframe(runoff_data)
  assert_chunk(runoff_data)
  assert_complete_date(runoff_data)
```

A notable quirk of the function is that the names of the header are put to lower
cases via the `tolower` function and possible leading zeros in the enumeration
of the basins are removed.

Currently it is not exported as users can use `xts` themselves perfectly well,
and it is felt that the function does not provide enough added value for the
user.

```{r}
  # everything is set tolower because we try to keep visCOS case insensitive
  runoff_data <- remove_leading_zeros(runoff_data)

  names(runoff_data) <- names(runoff_data) %>% tolower
  name_posix <- viscos_options("name_COSposix") %>% tolower
  runoff_data_as_xts <- xts(x = runoff_data[], # ,names(runoff_data) != name_posix
                            order.by = runoff_data[[name_posix]])
  #
  return(runoff_data_as_xts)
}
```

<!--chapter:end:LP-cook_data.Rmd-->

---
title: "Defensive Code"
author: "Daniel Klotz"
date: "8 Juli 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```

# Introduction
This section defines the defensive programming part of **visCOS**.
In this context, *defensive programing code* are all functions and scripts
dedicated to ensure that **visCOS** is working nicely even in unforeseen
circumstances. Often this means that the function has to return an error
if certain criteria are not met!

A useful example for such techniques is the `R` package
[`assertthat`](https://cran.r-project.org/web/packages/assertthat/index.html)

None of the functions are exported!

# Code

The subsequent functions are defined below

function | exported
------------- | -------------
`assert_chunk` | no
`assert_complete_date` | no
 `assert_dataframe` | no
`assert_of` | no

## `assert_chunk`
This function tests if there are any columns in the data.frame `runoff_data`,
which are not named after one of the 8 allowed column-names of **visCOS**.
**Note** however that the check is not case sensitive as all names in
`runoff_data` are set to lower cases with `tolower`.
```{r}
#' @import magrittr
assert_chunk <- function(runoff_data) {
  regEx <- get_regex_for_runoff_data()
  assertChunk <- names(runoff_data) %>% tolower %>% grepl(regEx,.)
  if (any(assertChunk == FALSE)) {
    stop("there is still unwanted columns in the data. Try: remove_junk")
  }
}
```

## `assert_complete_date`
Checks if all the date-/time- columns as defined within `viscos_options` are
existent in `runoff_data`. This is done by checking if the names of the
*COSdate* year column (as defined in `viscos_options`) and if the
*POSIXct* column (as defined in `viscos_options`) are there.
```{r}
assert_complete_date <- function(runoff_data) {
  OK_COSdate <- any(names(runoff_data) == viscos_options("name_COSyear"))
  OK_POSIXdates <- any(names(runoff_data) == viscos_options("name_COSposix"))
  # choose error messag depending on which columns are missing!
  if (!OK_COSdate & !OK_POSIXdates) {
    stop("No COSdates and no POSIXct-dates in the data!")
  } else if (OK_COSdate & !OK_POSIXdates) {
    stop("NO POSIXct fomrated column within the runoff_data!")
  } else if (!OK_COSdate & OK_POSIXdates) {
    stop("NO COSdate year within the runoff_data!")
  }
}
```

## `assert_dataframe`
Tests if `data` is a data.frame and returns an error if not.
```{r}
# uses stop if the input: "data" is not of class "data.frame"
assert_dataframe <- function(data) {
  require("tibble", quietly = TRUE)
  if ( !is.data.frame(data)&!is.tibble(data) ) stop("data needs to be a data_frame!")
}
```



<!--chapter:end:LP-defensive_code.Rmd-->

---
title: "Code for Exploring Objective Functions"
author: "Daniel Klotz"
date: "13 Juli 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```

# Introduction
This section defines the code of a [shiny app](http://shiny.rstudio.com/)
that lets users explore the (hydro-) graphs for the different basins in
conjunction with objective functions for the user-selected time-window. The
calculation of the objective functions are independent of the code defined in
the section about `main_of_compute`, since simpler constructions are preferable
in the case at hand and more information is given to the user.

The computations of the app are defined in the `server` part and the
appearance in the `ui`. 

# Example
In this chapter it is shown, how the function `explore_runoff` can be 
used to take a closer look at the data series you loaded. Only prerequirements 
are properly loaded data and correctly addressed `viscos_options`. Additionally, 
you can adapt the *color_* options in the `viscos_options`. Information on 
the *objective functions* can be found [here](ex-OF_explanation.html)

Running the `explore_runoff` with your data as input, a shiny app is 
started in a new window (in this case an example .jpg with explanations):
```{r,purl=FALSE, eval = FALSE}
viscos_options(color_o = "green", color_s = "red")
explore_runoff(runoff_example)
```

![](figures/eg_explore_basin.JPG)

Users can select different basins via the selection box (*# basins:*) on the
top-left and interactively zoom and move the graph in the center by clicking
on it or moving the date switches below the graph. While doing so the
objective functions (presented in the table below) are re-calculated for the
chosen time window. 


# Code
In the following paragraphs the code of the shiny app is defined.

## `explore_runoff`
This function represents the main part of the shiny app. 

```{r}
  #' explore runoff_data with Objective Functions
  #'
  #' Runs a Shiny App which can be used to get an overview of a runoff_data time
  #' series object.
  #'
  #' @param d_xts runoff_data formatted as time series
  #' 
  #' @import shiny 
  #' @import miniUI
  #' @importFrom xts xts
  #' @import dplyr
  #' @import magrittr
  #' @import dygraphs 
  #' @import hydroGOF
  #' @importFrom purrr map_df
  #' 
  #' @export
  #' 
  #' @examples
  #' # get example data,
  #' # explore the model performance
  #' d_runoff <- get_runoff_example()
  #' explore_runoff(d_runoff)
explore_runoff <- function(runoff_data,
                                   of_list = list(
                                     nse = of_nse, 
                                     kge = of_kge, 
                                     p_bias = of_pbias,
                                     r = of_cor
                                   ),
                                   start_date = NULL,
                                   end_date = NULL) {
  
```

At its current state the shiny app needs some pre-calculation, which are defined 
in this part of the code: 

- (I) Defensive code 
- (II) Transform data into `xts` (`d_xts`). 
- (III) Save numeration of basins within the variable `d_nums`.

**Note** that this approach forces users to enumerate their basins with
integers. `Doubles` would be transformed into integers by the `as.integer`
command!
```{r}
  # pre-sets
  # (I) Defense
  if (is.null(names(of_list))){
    names(of_list) <- paste("of", 1:length(of_list), sep = "_")
  }
  clean_runoff_data <- runoff_data %>% remove_leading_zeros
  if ( !viscos_options("name_COSposix") %in% names(clean_runoff_data) ) {
    clean_runoff_data %<>% prepare_complete_date
  }
  # (II)
  d_xts <- runoff_as_xts(clean_runoff_data)
  # (III)
  idx_names <- names(d_xts) %>%
    tolower %>% 
    grepl(viscos_options("name_o"),.)
  d_nums <- d_xts %>%
      names() %>%
      .[idx_names] %>%
      gsub("\\D","",.) %>%
      as.integer %>%
      unique
```

The server-side of the shiny app is rather lengthy but not too difficult.
The major readability problems occur because of the unusual formatting enforced
by shiny. The `reactive({})` marks all the interactive parts of the server.
The calculations are saved in the output-structures, which is handed over to the
`ui`. The graphs are saved/plotted to `output$hydrographs` and the objective
functions to `output$slctd_OF`. The start and end of the current time window is
handed  as string to the variable `output$selected_timewindow`. This requires
some transformation from the obtained `xts` values. This is done with
`strftime(., format = "%d %b %Y)`, which converts between character
representations and objects of `POSIXlt` and `POSIXct`.
```{r}
  server <- function(input, output, session) {
    # (I) get strings used in the naming of clean_runoff_data:
    unique_data_names <- names(clean_runoff_data) %>%
      gsub("\\d","",.) %>%
      tolower %>%
      unique
    x_string <- unique_data_names[ unique_data_names %>%
                                     grep(viscos_options("name_o"),.) ]
    y_string <- unique_data_names[ unique_data_names  %>%
                                     grep(viscos_options("name_s"),.) ]
    # (II) select data:
    '%&%' <- function(a,b) paste(a,b,sep = "") # %&% as substitute for function
    selector_x <- reactive({ x_string %&% input$basin_num %&% "$" }) # "$" terminates the searchstring; see regex
    selector_y <- reactive({ y_string %&% input$basin_num %&% "$" })
    selected_data <- reactive({
      select(clean_runoff_data,
             matches( selector_x() ),
             matches( selector_y() )
             ) %>%
        select(x = matches( selector_x() ),
               y = matches( selector_y() ))
    })
    # (III) create xts-formated table for use in dygraphs:
    xts_selected_data <- reactive ({
      xts(selected_data(),
          order.by = clean_runoff_data[[viscos_options("name_COSposix")]])
    })
    # (IV) create plots:
    output$hydrographs <- renderDygraph({
      dygraph( xts_selected_data() ) %>%
        dySeries("x",
                 label = visCOS::viscos_options("name_o"),
                 color = viscos_options("color_o")) %>%
        dySeries("y",
                 label = visCOS::viscos_options("name_s"),
                 color = viscos_options("color_s")) %>%
        dyRangeSelector(height = 20, strokeColor = "") %>% 
        dyCrosshair(direction = "vertical") %>%
        dyOptions(includeZero = TRUE) 
    })
    # (IV) get dygraph date bounds (switches):
    selcted_from <- reactive({
      if (!is.null(start_date)) {
        start_date
      } else if (!is.null(input$hydrographs_date_window)) {
        input$hydrographs_date_window[[1]]
      }
    })
    selcted_to <- reactive({
      if (!is.null(end_date)) {
        end_date
      } else if (!is.null(input$hydrographs_date_window)) {
        input$hydrographs_date_window[[2]]
      }

    })
    # (V) extract time_window for the stats header:
    output$selected_timewindow <- renderText({
      if (!is.null(input$hydrographs_date_window))
        paste(strftime(selcted_from(), format = "%d %b %Y"),
              "-",
              strftime(selcted_to(), format = "%d %b %Y"),
              sep = " ")
    })
    # (VI) calculate stats:
    sub_slctd <- reactive({
      if (!is.null(input$hydrographs_date_window))
        xts_selected_data()[paste(strftime(selcted_from(), format = "%Y-%m-%d-%H-%M"),
                               strftime(selcted_to(), format = "%Y-%m-%d-%H-%M"),
                               sep = "/")]
    })
    out_of <- reactive({
      if (!is.null(input$hydrographs_date_window)) {
          map_df(of_list, function(of_,x,y) of_(x,y), 
                 x = sub_slctd()$x, 
                 y = sub_slctd()$y ) #serve_of( sub_slctd()$x,sub_slctd()$y )
      }
    })
    
    output$slctd_OF <- renderTable(out_of())
    # (VII) exit when user clicks on done 
     # When the Done button is clicked, return a value
    observeEvent(input$done, {
      returnValue <- list(
        selected_time = c(strftime(selcted_from(), format = "%Y-%m-%d-%H-%M"),strftime(selcted_to(), format = "%Y-%m-%d-%H-%M")),
        selected_data = data.frame(date = index(sub_slctd()),
                                   coredata(sub_slctd())),
        selected_of = out_of()
      )
      stopApp(returnValue)
    })
  }
```

The `miniUI` is quite spartan. It consists a input selection (`selectInput`),
which allows user to select different basins, the `dygraph` output `hydrographs`
for the interactive exploration of the $x$ and $y$ data and a formatted table
output (`slctd_OF`), which displays the different objective functions (defined
in `explore_of`). The `hr` command block separates this table from the
`dygraph` output via a small-grey line.
```{r}
  ui <- miniPage(
    miniButtonBlock(selectInput("basin_num",
                                "# basin:",
                                choices = d_nums,
                                selected = 1, 
                                selectize = FALSE)),
    miniContentPanel(
      fillCol(
        flex = c(4,1),
        dygraphOutput("hydrographs", width = "100%", height = "100%"),
        fillCol(
          align = "center",
          textOutput("selected_timewindow"),
          tableOutput("slctd_OF")
        )
      )
    ),
    gadgetTitleBar("test")
  )
```

```{r}
dyCrosshair <- function(dygraph, 
                        direction = c("both", "horizontal", "vertical")) {
  dyPlugin(
    dygraph = dygraph,
    name = "Crosshair",
    path = system.file("examples/plugins/crosshair.js", 
                       package = "dygraphs"),
    options = list(direction = match.arg(direction))
  )
}
```


```{r}
  runGadget(ui,server)
}
```


<!--chapter:end:LP-explore_runoff.Rmd-->

---
title: "helpers"
author: "Daniel Klotz"
date: "8 Juli 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```

# Introduction
This section collects small and helpful functions/scripts that are used
throughout **visCOS**.

None of the functions is exported!

# Code
The subsequent functions are defined below

function | exported
------------- | -------------
`get_regex_for_runoff_data` | no
`get_basin_numbers` | no
`set_panel_size`| no

## `get_regex_for_runoff_data`
This function can be called to get the names of the 8 allowed column-names
within **visCOS**. `get_regex_for_runoff_data` takes no input, as it gets the
information directly from the global options (see: *viscos_options section*).
```{r}
get_regex_for_runoff_data <- function() {
  regex_pattern <- paste("^",viscos_options("name_COSyear"),"$|",
                         "^",viscos_options("name_COSmonth"),"$|",
                         "^",viscos_options("name_COSday"),"$|",
                         "^",viscos_options("name_COShour"),"$|",
                         "^",viscos_options("name_COSmin"),"$|",
                         viscos_options("name_o"),".*|",
                         viscos_options("name_s"),".*|",
                         viscos_options("name_COSposix"),"|",
                         viscos_options("name_COSperiod"),
                         sep = "")
  return(regex_pattern)
}
```


## `get_basin_numbers`
This function fetches the number of basins from the provided data.frame
(`runoff_data`) by removing all the non-digits characters from the column names.
```{r}
get_basin_numbers <- function(runoff_data) {
  require("magrittr", quietly = TRUE)
  assert_dataframe(runoff_data)
  assert_chunk(runoff_data)
  #
  d_names <- names(runoff_data)
  d_nums <- d_names  %>% gsub('\\D','',.) %>% unique
  d_nums <- d_nums[!(d_nums == "")] %>% as.integer
  return(d_nums)
}


```


## `set_panel_size`
Klotz: I honestly forgot what this function does! But I think ti is a good helper
I need to look it up, but am not ready yet! I roughly remember that setting
graphical options with ggplot is a mess, and this is a function, which
might solves a lot. However, I am not sure! 
```{r}
set_panel_size <- function(p=NULL, g=ggplotGrob(p), file=NULL,
                           margin = unit(1,"mm"),
                           width=unit(3, "cm"),
                           height=unit(2, "cm")){

  panels <- g$layout$name=="panel"
  panel_index_w<- g$layout$l[panels]
  panel_index_h<- g$layout$t[panels]
  nw <- length(unique(panel_index_w))
  nh <- length(unique(panel_index_h))
  g$widths[panel_index_w] <- rep(list(width), nw)
  g$heights[panel_index_h] <- rep(list(height), nh)
  class(g) <- c("fixed", class(g), "ggplot")
  if(!is.null(file))
    ggsave(file, 
           g,
           width = convertWidth(sum(g$widths) + margin,
                                unitTo = "in", valueOnly = TRUE),
           height = convertHeight(sum(g$heights) + margin,
                                  unitTo = "in", valueOnly = TRUE))
  g
}
```

<!--chapter:end:LP-helpers.Rmd-->

---
title: "Calculation of Objective Functions"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "12 Juli 2016"
output:
  html_document:
    number_sections: yes
  pdf_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```

# Introduction
This chapter explains the code to calculate the main objective functions $of$ 
used in visCOS. As explained in [respective section](LP-of.html) objective 
functions are a pivotal part of model calibration. As of now, **visCOS** focuses
on 4 main objective function: NSE, KGE, Pearsons Correlation and the Percentage 
bias (the respective definitions are given [here](LP-of.html)).

The main objective functions for the overall data and the marked periods 
can be computed through the function `main_of_compute`. In order to run the 
function the period have to be marked first, e.g. through the `mark_periods`
function. Additionally, **visCOS** already provides two differnt options 
to create plots for the main objective functions: `main_of_rasterplot` 
and `main_of_barplot`. Both functions create a list with 4 ggplots. Each entry
in the list corresponds to one of the main objective functions and both lists 
can be saved to html ebmedded .jpgs with the [`serve` function](LP-serve.html).

**Examples:**

Computing the main objective functions
```{r, message=3, purl=FALSE, eval=TRUE}
require(visCOS)
require(magrittr)
of_values <- get_runoff_example() %>%
  mark_periods() %>%
  main_of_compute()
of_values
```

Plotting the results of main objective function with barplots:
```{r, message=3, purl=FALSE, eval=TRUE}
of_values <- get_runoff_example() %>% 
  mark_periods() %>%
  main_of_barplot() %>%
  extract2(1) %>% 
  plot()
```

Plotting the results of main objective function with a raster:
```{r, message=3, purl=FALSE, eval=TRUE}
of_values <- get_runoff_example() %>% 
  mark_periods() %>%
  main_of_rasterplot() %>%
  extract2(2) %>% 
  plot()
```

# Code
In this section the code for the `main_of` function familiy is defined

## Compute the Main Objective Functions
The purpose of this function is to extract a the main of objective functions 
from the `COSERO` data.frame. The objective functions are extracted for each
basin seperately and computed for the entire length of the data, aswell as 
for each period separately.
```{r}
#' Get basic objective function for runoff_data
#'
#' Calculate basic objective functions(NSE, KGE, percentage BIAS, Correlation) 
#' for every basin and the chosen periods.
#'
#' @param runoff_data runoff_data data.frame.
#' @return list of basic objective function evaluated for the different
#' hydrological years and over the whole timespan.
#' 
#' @import hydroGOF 
#' @import dplyr
#'
#' @export
main_of_compute <- function(runoff_data) {
  assert_dataframe(runoff_data)
  if( !exists(viscos_options("name_COSperiod"), where = runoff_data) ) {
    stop("Error! Period-Column missing in runoff_data; use `mark_periods`")
  }
```

The computational part of the function works as follows. In step (I) the
non-marked periods of `runoff_data` (columns of
`viscos_options("name_COSperiod")` which are smaller then 0) are excluded 
from further calculations. The thereby obtained data.frame is named
`evaluation_data`. 
```{r}
  evaluation_data <- 
    runoff_data[ runoff_data[[viscos_options("name_COSperiod")]] > 0, ]
```

Extract the important information for the calculations:
```{r}
  number_of_basins <- evaluation_data %>%
    names %>%
    unique %>%
    grepl(viscos_options("name_o"), ., ignore.case = TRUE) %>%
    sum 
  periods_in_data <- evaluation_data %>%
    magrittr::extract2(viscos_options("name_COSperiod")) %>% 
    unique
  number_of_periods <- periods_in_data %>% length
```

Next, compute the overall objective functions. This is done by copying all
`viscos_options("name_o")` columns into the `temp_x` variable and all
`viscos_options("name_s")` into the `temp_y` variable. 
```{r}
  temp_x <- dplyr::select(evaluation_data,starts_with(viscos_options("name_o"))) %>%
    unname
  temp_y <- dplyr::select(evaluation_data,starts_with(viscos_options("name_s"))) %>%
    unname
  nse_ <- hydroGOF::NSE(temp_y,temp_x)
  kge_ <- hydroGOF::KGE(temp_y,temp_x)
  p_bias_ <- hydroGOF::pbias(temp_y,temp_x)
  corr_ <- cor(temp_y,temp_x) %>% diag(.)

```

Finally, a period-wise a repetition of the previous step is done to get the
`main_of` for each marked period (see: `mark_periods`):
```{r}
  # Calulcated period-vise objective functions
    # pre allocation of periodic variables:
    NSE_period <- matrix(nrow = number_of_periods, ncol = as.integer(number_of_basins), data = NA)
    KGE_period <- NSE_period
    p_bias_period <- NSE_period
    CORR_period <- NSE_period
    # calculation loop # proabbly slow
    for (k in 1:number_of_periods) {
      temp_x <- dplyr::filter(evaluation_data,period == periods_in_data[k]) %>%
        dplyr::select(.,starts_with(viscos_options("name_o"))) %>%
        unname
      temp_y <- dplyr::filter(evaluation_data,period == periods_in_data[k]) %>%
        dplyr::select(.,starts_with(viscos_options("name_s"))) %>%
        unname
      NSE_period[k,1:number_of_basins] <- hydroGOF::NSE(temp_y,temp_x)
      KGE_period[k,1:number_of_basins] <- hydroGOF::KGE(temp_y,temp_x)
      p_bias_period[k,1:number_of_basins] <- hydroGOF::pbias(temp_y,temp_x)
      CORR_period[k,1:number_of_basins] <- cor(temp_y,temp_x) %>% diag(.)
    }
  #
  obj_names <- c("NSE","KGE","p_bias","CORR", 
                    paste("NSE_period",1:number_of_periods,sep="."), 
                    paste("KGE_period",1:number_of_periods,sep="."),
                    paste("p_bias_period",1:number_of_periods,sep="."),
                    paste("CORR_period",1:number_of_periods,sep=".")
  )
  obj_fun <- data.frame(of = obj_names, 
                        basin = rbind(nse_,
                                      kge_,
                                      p_bias_,
                                      corr_,
                                      NSE_period,
                                      KGE_period,
                                      p_bias_period,
                                      CORR_period),
                        row.names = NULL)
  return(obj_fun)
}

```

## Plotting
In this section the code for plotting the main_of is defined. There is no 
wrapper function, but a central explenation for the plotting of the main 
valuse is prodied:
```{r}
#' Plot main objective fucnction values
#'
#' Currently two options for plotting the main objectives are provided by 
#' visCOS: Plotting the differnet objective functions values as a set of 
#' barplots \code{barplot_of} and plotting a summary table in form of 
#' a large raster of all the objective fucntion values \code{rasterplot_of}.
#' 
#' @name plot_main_of 
NULL 
```

One can define the to-be plotted objective function with the character 
`of_name`. 


Then some housekeeping needs to be undertaken. For the computations and 
selections all names are set to lower case (`tolower`), because **visCOS** works
case-insensitive. The basin enumeration `num_basins` is obtained with
the function [`get_basin_numbers`](LP-helpers.html).  

### Bar Plot 
```{r}
#' Barplot for the Main Objective Function Values 
#' 
#' @rdname of_overview
#' @export
main_of_barplot <- function(runoff_data) {
  main_of_names <- c("NSE","KGE","CORR","p_bias")
  assert_dataframe(runoff_data)
  of <- main_of_compute(runoff_data)
  # calculate objective functions
  num_basins <- ncol(of) - 1
  # melt the of:
  # a bit of a mess, and there is probaly a better solution...
  melted_of <- suppressMessages( reshape2::melt(of) ) %>% 
    mutate(of_group = ifelse(of %>% as.character %>% startsWith(.,main_of_names[1]),main_of_names[1],
                             ifelse(of %>% as.character %>% startsWith(.,main_of_names[2]),main_of_names[2],
                                    ifelse(of %>% as.character %>% startsWith(.,main_of_names[3]),main_of_names[3],
                                           ifelse(of %>% as.character %>% startsWith(.,main_of_names[4]),main_of_names[4],NA))))) 
  # define plot-list function
  plotlist_fun_barplot <- function(of_name) {
    of_to_plot <- melted_of %>% filter( of_group == of_name)
    if (of_name == "p_bias") {
      gglimits <- c(-viscos_options("of_limits")[2]*100,
                   viscos_options("of_limits")[2]*100)

    } else {
      gglimits <- viscos_options("of_limits")
    }
    plt_out <- ggplot(data = of_to_plot) +
      geom_bar(stat = "identity",
               position = "identity",
               aes(x = of,
                   y = value, 
                   fill = value)) +
      facet_wrap(~ variable, ncol = 1) + 
      ggtitle(of_name) +
      ylim(gglimits)
    return(plt_out)
  }
  # apply plot.list function to the different groupings
  plot_list <- lapply(main_of_names,plotlist_fun_barplot)
  names(plot_list) <- main_of_names
  return(plot_list)
}
```

### Raster-Plot
```{r}
#' Barplot for the Main Objective Function Values 
#' 
#' @rdname of_overview
#' @import pasta
#' @export
main_of_rasterplot <- function(runoff_data) {
  main_of_names <- c("NSE","KGE","CORR","p_bias")
  regex_main_of <- main_of_names %&% ".*"
  assert_dataframe(runoff_data)
  of <- main_of_compute(runoff_data)
  #
  plot_list <- lapply(regex_main_of,function(x) plot_fun_raster(x,of)) %>% 
    set_names(main_of_names)
  return(plot_list)
}
```

**Raster-Plot for one Basin**

```{r}
  plot_fun_raster <- function(regex_single_of,of) {
    if (regex_single_of == "p_bias.*") {
      gglimits <- c(-viscos_options("of_limits")[2]*100,
                    viscos_options("of_limits")[2]*100)
    } else {
      gglimits <- viscos_options("of_limits")
    }
    # 
    plot_data <- of %>% 
      extract(grep(regex_single_of,.$of), ) %>% 
      cbind(.,facets = c("overall", rep("period",(nrow(.) - 1)))) %>% 
      reshape2::melt(., id.vars = c("of","facets")) %>% 
      reverse_basin_levels %>% 
      reverse_facetting_levels %>%
      dplyr::mutate(value = pmax(value,gglimits[1])) %>% 
      dplyr::mutate(value = pmin(value,gglimits[2])) %>% 
      dplyr::mutate(value = round(value,2))
    #
    plt_out <- ggplot(plot_data, aes(of,variable, fill = value), environmnet = environment()) +
      geom_raster(position = "identity") +
      coord_fixed(ratio = 5)  + 
      facet_grid(~ facets,  scales = "free_x", space = "free") +
      theme( legend.position = "none")  +
      geom_tile(color = "white", size = 0.25 ) +
      geom_text(aes(of,variable, label = as.character(value,2)), color= "black") 
    return(plt_out)
  }

  reverse_basin_levels <- function(plot_data) {
    plot_data$variable <- factor(plot_data$variable,
                                 levels = plot_data$variable %>%
                                   levels() %>% 
                                   rev() )
    return(plot_data)
  }
  reverse_facetting_levels <- function(plot_data) {
    plot_data$facets <- factor(plot_data$facets,
                                 levels = plot_data$facets %>%
                                   levels() %>% 
                                   rev() )
    return(plot_data)
  }
```



<!--chapter:end:LP-main_of.Rmd-->

---
title: "Ojective Functions"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "14 Juli 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```


# Introduciton
This chapter defines the objective functions that are used in **visCOS**.

Objective functions, in short $of$, are an important part of the hydrological 
model calibration. Their importance arises from the approximate nature of the 
models and the large uncertainties of the process. Hydrological models are not 
only imperfect, in the sense that they simplify nature, but in most cases 
structurally different than the reality so that different models or their 
respective parametrisations approximate the hydrograph equally well. Thus, 
over the time a pletora of objective fucntions have been developed to either 
make the model-results better interpretable/comparable or to adress specific 
problems of given objective functions. 

# Objective Functions 
This section defines the code for different objective functions. If possible the
calculation is done with the help of the `hydroGOF` package, if not an R-code
solution is tried. 
Currently 4 main objective functions are provided in **visCOS**. They can
be directly extracted from the `cos_data` data.frame via the 
[`main_of_`](LP-main_of.html) functions. Other objective functions are provided 
to, but no special extraction and visualisation functions are provided for them. 

For the explanation and definition of the objective fucntion it is assumed that 
 $o$ are the observations (defined by `name_o` in visCOS) and $s$ are the 
 simulation(defined by `name_s` in visCOS).
```{r}
#' Objective Functions
#' 
#' Different objective Functions, provided by visCOS. A detailed description 
#' of each of the provided objective function is provided in the respective
#' vignette
#' 
#' @param o The reference data or observations (o_data)
#' @param s The created data or the simulations (s_data)
#' @name of_overview
NULL
```

## Main Objective Functions
Currently the main objective functions are the Nash-Sutcliffe Efficiency, 
the Kling-Gupta Efficiency, the percentage bias and the correlation.

### Nash-Sutcliffe Efficiency
The Nash-Sutcliffe Criterion $NSE$ is by far the most used efficiency criterion
in hydrology. In the hydrological context $o$ usually represents a set of
runoff-observation and $s$ a set of simulations. The $NSE$ is defined in the
same way as the general definition of the coefficient of determination $R^2$:

$$ NSE = \frac{\sum_{t=1}^T \big( o(t)-s(t) \big)^2}
              {\sum_{t=1}^T \big( o(t)-\bar{o} \big)^2} . $$

The variable $\bar{o}$ represents the average of $o$. The $NSE$
can be seen as the relational the estimator $s$ and the estimator
resulting form the average of the data. It can can have values between minus 
infinity and 1 with 1 being the perfect fit, 0 when the mean of $s$ is as 
good as the mean of $o$ and negative values are even worse.

The code for the $NSE$ computation is:

```{r}
#' Nash-Sutcliffe Efficiency
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_nse <- function(o,s) {
  as.numeric( NSE(s,o) )
}
```


### Kling-Gupta Efficiency
The Kling-Gupta Efficiency $KGE$ was introduced by Gupta et al. (2009) to
alleviate some of the shortcomings of the $NSE$. In their paper they argue
why the $NSE$ tends to overate simulations with small variance
(note: in the context of the paper $\textrm{simulations} = s$) and
propose their efficiency criterion instead.

The $KGE$ is defined as:

$$ KGE = 1 - ED, $$

with

$$ ED = \sqrt{\big(corr(o,s)-1 \big)^2 +
              \big(\alpha(o,s)-1 \big)^2 +
              \big(\beta(o,s)-1 \big)^2 }. $$

In which $\alpha(o,s) = \frac{\sigma_s}{ \sigma_o }$ is the standard deviation
$\sigma$ of $s$ divided by the $\sigma$  of $o$, $\beta(o,s) = \mu_s / \mu_o$ 
with$\mu$ being the arithmetic mean and $corr(o,s)$ as the 
Pearson's correlation coefficient (see below). The value range and the 
quality is similar to the $NSE$. 

The code for the $KGE$ computation is:
```{r}
#' Kling-Gupta Efficiency
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_kge <- function(o,s) {
  as.numeric( KGE(s,o) )
}
```

### Percentage Bias
The percentage of bias $p_{bias}$ is defined as the sum of the differences
between $o$ and $s$ divided by the sum of $o$:

$$ p_{bias} = 100*\frac{\sum_{t=1}^T [ o(t)-s(t) ] }{\sum_{t=1}^T o(t)}. $$

The $100*$ is just a scaling factor applied to express $p_{bias}$ as a percentage.

The code for the $p_{bias}$ computation is:
```{r}
#' Percentage Bias 
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_p_bias <- function(o,s) {
  as.numeric( pbias(s,o) )
}
```

### Pearson's correlation coefficient
Pearson's correlation coefficient, $r$ or $corr(o,s)$, is a measure of the 
linear relationship between $o$ and $s$. It is defined as:

$$ r \equiv corr(o,s) = \frac{cov(o,s)}{\sigma_s*\sigma_o}, $$

where $cov(...)$ denotes the covariance. The correlation
coefficient can take on values between -1 and 1. The former corresponds to an
inverse and the latter to a direct relationship and the closer the values
is to zero the weaker is the implied correlation. 

The code for the correlation is:
```{r}
#' Correlation
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_cor <- function(o,s) {
  diag( cor(o,s) )
}
```

## Ohter Objective Functions 

Descriptions shall follow

### Root Mean Sqaured Error

$$ \frac{\sum_{t=1}^T \big( o(t)-s(t) \big)^2}
              {T} $$
```{r}
#' Root Mean Sqaured Error 
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_rmse <- function(o,s) {
  as.numeric( rmse(s,o) )
}
```

### Inverted Nash-Sutcliffe Efficiency

$$ nse^{-1} = \frac{\sum_{t=1}^T \big( s(t)-o(t) \big)^2}
              {\sum_{t=1}^T \big( s(t)-\bar{s} \big)^2} $$
```{r}
#' Inverted Nash-Sutcliffe Efficiency
#' 
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_invert_nse <- function(o,s) {
  as.numeric( NSE(o,s) )
}
```

### Ratio of the Standard Deviations

$$ rsd = \frac{\sigma_s}{ \sigma_o } $$
```{r}
#' Ratio of Standard Deviations
#'
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_rsd <- function(o,s) {
  as.numeric( rSD(s,o) )
}
```

### Ratio of the Means

$$ rmeans = \mu_s / \mu_o$$
```{r}
#' Ratio of Means
#'
#' @rdname of_overview
#' @export
of_rmeans <- function(o,s) {
  as.numeric( mean(s)/mean(o) )
}
```

### Volumetric Efficiency
The volumetric efficency, $VE$, uses the absolute distance between observation ans 
simulation instead of the quadratic and is bound between 0 to 1. 

$$ VE = 1- \frac{\sum_{t=1}^T abs\big( s(t)-o(t) \big)}
                {\sum_{t=1}^T o(t) } $$

```{r}
#' Volumetric Efficiency
#'
#' @rdname of_overview
#' @import hydroGOF
#' @export
of_ve <- function(o,s) {
  as.numeric( VE(s,o) )
}
```

# References 
- **Percentage Bias:** Yapo P. O., Gupta H. V., Sorooshian S., 1996. Automatic calibration of conceptual rainfall-runoff models: sensitivity to calibration data. Journal of Hydrology. v181 i1-4. 23-48
- **Nash-Sutcliffe Efficiency:** Nash, J. E. and J. V. Sutcliffe (1970), River flow forecasting through conceptual models part I -A discussion of principles, Journal of Hydrology, 10 (3), 282-290 
- **Kling-Gupta Efficiency:** Gupta, Hoshin V., Harald Kling, Koray K. Yilmaz, Guillermo F. Martinez. Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling. Journal of Hydrology, Volume 377, Issues 1-2, 20 October 2009, Pages 80-91. DOI: 10.1016/j.jhydrol.2009.08.003. ISSN 0022-1694
- **Volumetric Efficency:** Criss, R. E. and Winston, W. E. (2008), Do Nash values have value?
Discussion and alternate proposals. Hydrological Processes, 22: 2723-2725. doi: 10.1002/hyp.7072

<!--chapter:end:LP-of.Rmd-->

---
title: "Plotting Runoff Peaks Plots"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "22 September 2016"
output:
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE, fig.align = 'center')
```

# Introduction
The function `peak_plot` lets users explore the highest events in 
among the available basins. It provides a list of [ggplot2](http://ggplot2.org/) 
plots, containing an overview plot (`overview`), a scatter plot (`scatter`) 
and detail plots of the individual events (`event_plot`). Instead of 
explaining the properties of each plot in detail it is best to get an intuition 
of the function by looking at some examples. 

## Examples:
For the examples 10 events are extracted from a runoff example
```{r, eval = TRUE, purl=FALSE}
  require(visCOS)
  runoff_data <- get_runoff_example()
  peakplots <- peak_plot(runoff_data, n_events = 10L)
  
```

The `peakplots` list does now contain plots for each basin within the 
`runoff_data` data.frame: 
```{r, eval = TRUE, purl=FALSE}
  names(peakplots)
```

For each basin the a set of plots (`overview`,`scatter`,`event_plot`) are saved 
within a list for each basin. In the following the plots for basin 1 are shown:
```{r, eval = TRUE, purl=FALSE}
  names(peakplots$basin0001)
```

The `overview` plot shows the entire time series of `data1` and `data2` of the 
basin. The found events are marked with black dots. The `overview` plot for 
basin 1 is:
```{r, eval = TRUE, purl=FALSE}
  peakplots$basin0001$overview
```

The `scatter` plot shows the found events within a scatter plot, where  `data1` 
is the x-axis and `data2` on the y-axis. In the followin an example for basin 1
is given.
```{r, eval = TRUE, purl=FALSE}
  peakplots$basin0001$scatter
```

Detail plots for each of the found events are given in form of the `event_plot`
objects. Here an example:
```{r, eval = TRUE, purl=FALSE}
  peakplots$basin0001$event_plot5
```


# Code
This part of the document defines the code of `peak_plot`
```{r}
#' Plot List for Runoff Peaks 
#' @export
#' 
#' @import ggplot2 
#' @import dplyr 
#' @import magrittr
#' @importFrom tibble tibble
peak_plot <- function(runoff_data,
                                 n_events= 10L,
                                 window_size = 24L) {
  # pre:
  assert_dataframe(runoff_data)
  n_events_int <- as.integer(n_events) 
  window_size_int <- as.integer(window_size)
  if( is.na(n_events_int)  | 
      is.nan(n_events_int) | 
      is.infinite(n_events_int) | 
      !is.integer(n_events_int) ) {
    stop("n_events is ill defined")
  }
  if( is.na(window_size)  | 
      is.nan(window_size) | 
      is.infinite(window_size) | 
      !is.integer(window_size) ) {
    stop("window_size is ill defined")
  }
  data1 <- runoff_data %>%
     select( starts_with(viscos_options("name_o")) )
  data2 <- runoff_data %>%
     select( starts_with(viscos_options("name_s")) )
  data_numbers <- names(data1) %>%
    gsub(viscos_options("name_o"),"",.,ignore.case = TRUE) %>% 
    gsub("\\D","",.,ignore.case = TRUE)
  # make plotlist: 
  plotlist <- lapply(1:ncol(data1), function(x) plotlist_one_basin(data1[,x],
                                                                   data2[,x],
                                                                   n_events_int, 
                                                                   window_size_int)) %>%
    set_names(.,paste("basin", data_numbers, sep =""))
  return(plotlist)
}
```

## Generating the Plots for one basin. 
This is the function for generating the different plots for one basin. 
At first the provided time series are groupded into a tibble, then the 
peaks of the observations are obtained via the peak_finder function and 
organised.Then `ggplot2` is used for plotting. 
```{r}
plotlist_one_basin <- function(qobs,qsim,n_events_int,window_size_int) {
  single_data <- tibble::tibble(time = as.integer(1:length(qobs)),
                                obs = as.double(qobs),
                                sim = as.double(qsim))
  #
  peak_idx <- find_peaks(single_data$obs,m = window_size_int)
  peak_organised <- tibble::tibble(idx = as.integer(peak_idx), 
                           peak_obs = single_data$obs[peak_idx], 
                           peak_sim = single_data$sim[peak_idx])
  highest_peaks_organised <- peak_organised$peak_obs %>% 
    sort(decreasing = TRUE) %>% 
    .[1:n_events_int] %>%
    '%in%'(peak_organised$peak_obs,.) %>% 
    which( . ) %>% 
    peak_organised[., ]
  #
  overview_plot <- ggplot() +
    geom_line(data = single_data,aes(x = time, y = sim), col = viscos_options("color_s")) + 
    geom_line(data = single_data,aes(x = time, y = obs), col = viscos_options("color_o")) + 
    geom_point(data = highest_peaks_organised, aes(idx, peak_obs))
  overview_scatter <- ggplot() + 
    geom_point(data = single_data, aes(obs,sim), color = "#DDDDDD") +
    geom_abline() +
    geom_point(data = highest_peaks_organised, aes(peak_obs,peak_sim), size = 4) +
    expand_limits(x = 0, y = 0) 
  sub_plots <- lapply(1:nrow(highest_peaks_organised),
                      function(x) sub_peakplot_fun(x,window_size_int,highest_peaks_organised,single_data) ) %>%
    set_names(.,paste("event_plot",1:length(.),sep=""))
  return(overview = append(list(overview = overview_plot,scatter = overview_scatter), sub_plots))
}
```

## Function to find peaks
The function for finding the peaks was proposed and developed by 
Propsoed by the cross validated user "stas g" in [this](http://stats.stackexchange.com/questions/22974/how-to-find-local-peaks-valleys-in-a-series-of-data)
thread.  
This is by far not the only option/possibility to appraoch the peak finding task. 
Other nice ideas for finding peaks can be found in [this](http://stats.stackexchange.com/questions/36309/how-do-i-find-peaks-in-a-dataset)
cross validated thread. 

```{r}
  ####
  # peak finder function: 
  find_peaks <- function (x, m = 3){
    shape <- diff(sign(diff(x, na.pad = FALSE)))
    pks <- sapply(which(shape < 0), FUN = function(i){
      z <- i - m + 1
      z <- ifelse(z > 0, z, 1)
      w <- i + m + 1
      w <- ifelse(w < length(x), w, length(x))
      if(all(x[c(z : i, (i + 2) : w)] <= x[i + 1])) return(i + 1) else return(numeric(0))
    })
    pks <- unlist(pks)
    pks
  }
```

## Subplot Function 
This function is a wrapper around ggplot, which is used to generate the 
individual event plots. 
```{r}
  ####
  # sub plot function:
  sub_peakplot_fun <- function(x,window_size,highest_peaks_organised,peak_data) {
    point <- highest_peaks_organised[x,]
    plot_sub <- ggplot() +
      geom_line(data = peak_data[(point$idx - window_size):(point$idx + window_size),],
                aes(x = time, y = sim), 
                col = "orange") + 
      geom_line(data = peak_data[(point$idx - window_size):(point$idx + window_size),],
                aes(x = time, y = obs), 
                col = "steelblue") + 
      geom_point(data = point, aes(idx, peak_obs))
    return(plot_sub)
  }
```









<!--chapter:end:LP-peak_plot.Rmd-->

---
title: "serve"
author: "Daniel Klotz"
date: "07 Oktober 2016"
output: html_document
---

```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE, fig.align = 'center')
```

Possibility to save plotlists into jpgs and create a linked html file. 

# code 
```{r}
#' Serve is still beta 
#' 
#' More description shall follow 
#' @export
serve <- function(plotlist,path = "", fig_width = 800L, fig_height = 500L) {
  hmtl_filename <- "summary"
  # establish html-file in chosen folder
  '%&%' <- function(a,b) paste(a,b,sep = "") # helper for easiser string concatenation
  fileConn <- file(path %&% hmtl_filename %&% ".html" , "w")
  # write html header
  #writeLines(text = '<!DOCTYPE html>',fileConn)
  writeLines(text = "<HEAD>",fileConn)
  writeLines(text = "  <STYLE type='text/css'>",fileConn)
  writeLines(text = "    H1 { text-align: center}",fileConn)
  writeLines(text = "  </STYLE>",fileConn)
 writeLines(text = "</HEAD>",fileConn) 
  #writeLines(text = '<html>',fileConn)
  writeLines(text = '<body>',fileConn)
  # check which kind of plotlsit we are dealing with: 
  if ( all(names(plotlist) == c("NSE","KGE","p_bias","CORR")) ) {
    list_to_plot <- plotlist

  } else if ( all(grepl("basin",names(plotlist1))) ) {
    list_to_plot <- unlist(plotlist,recursive = FALSE)
  } else {
    stop("plotlist not known!")
  }
  num_plots <- length(list_to_plot)
  figure_names <- names(list_to_plot)
  ## save everything localy & link it within the html file
  jpg_filenames <- "figure"
  
  for (i in 1:num_plots) {
    writeLines(text = "<H1>" %&% figure_names[i] %&% "</H1>",fileConn)
    plt_name <- jpg_filenames %&% i %&% ".jpg"
    plt_pathANDname <- path %&% plt_name
    plt_hmtlInfos <- "<img src=\"" %&% plt_name %&% '" alt="plotting_failed" style="width:800px;height:500px;">'
    #
    writeLines(text = "<H1>" %&% plt_hmtlInfos  %&% "</H1>", fileConn)
    jpeg(file = plt_pathANDname, width = fig_width, height = fig_height, units = "px")
      plot(list_to_plot[[i]])
    dev.off()
  }
  close(fileConn)
}
```


<!--chapter:end:LP-serve.Rmd-->

---
title: "Time Aggregates"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "22 September 2016"
output:
  html_document:
    number_sections: yes
---



```{r setup, include=FALSE, purl=FALSE}
  knitr::opts_chunk$set(eval = FALSE, tidy = FALSE, fig.align = 'center')
```

# Introduction
In hydrology it is often usefull to summarise the data respect to a 
given time dimension. In **visCOS** this can be done by using the 
`aggregate_time` function. The function takes 
[COSERO data.frame](cook_data.html) and aggregates them according to a chosen
time dimension. Note, that the name of the dimension can be specified via the 
[options](LP-viscos_options.html).

## Examples
```{r, eval = TRUE, purl=FALSE}
  require(ggplot2, quietly = TRUE)
  require(visCOS, quietly = TRUE)
```

Daily runoff aggregation: 
```{r, eval = TRUE, purl=FALSE}
  cos_data <- visCOS::get_runoff_example()
  runoff_aggregate_dd <- aggregate_time(cos_data, "dd")
  # plot data:
  ggplot(runoff_aggregate_dd) + 
      geom_line(aes(x = idx, y = value, col = obs_sim)) + 
      scale_colour_manual(values = c(viscos_options("color_o"),
                                     viscos_options("color_a"))) + 
      facet_wrap( ~ basin,ncol = 1) +
      theme_minimal()
```

Monthly runoff aggregation: 
```{r, eval = TRUE, purl=FALSE}
  runoff_aggregate_mm <- aggregate_time(cos_data, "mm")
  # plot data:
  ggplot(runoff_aggregate_mm) + 
      geom_line(aes(x = idx, y = value, col = obs_sim)) + 
      scale_colour_manual(values = c(viscos_options("color_o"),
                                     viscos_options("color_s"))) + 
      scale_x_discrete(limits = runoff_aggregate_mm$time_aggregate) +
      facet_wrap( ~ basin, scales = "free") + 
      theme_minimal()
```

Yearly runoff aggregation: 
```{r, eval = TRUE, purl=FALSE}
  runoff_aggregate_yyyy <- aggregate_time(cos_data, "yyyy")
  # plot data:
  ggplot(runoff_aggregate_yyyy) + 
    geom_point(aes(x = idx, y = value, col = obs_sim)) + 
    scale_colour_manual(values = c(viscos_options("color_o"),
                                   viscos_options("color_s"))) + 
    facet_wrap( ~ basin) +
    scale_x_discrete(limits = runoff_aggregate_yyyy$time_aggregate,  
                    labels = abbreviate) + 
    theme_minimal()
```

Yearly and monthly runoff aggregation: 
```{r, eval = TRUE, purl=FALSE}
  runoff_aggregate_yyyymm <- aggregate_time(cos_data, "yyyy-mm")
  # plot data:
  ggplot(runoff_aggregate_yyyymm) + 
    geom_line(aes(x = idx, y = value, col = obs_sim)) + 
    scale_colour_manual(values = c(viscos_options("color_o"),
                                   viscos_options("color_s"))) + 
    scale_x_discrete(limits = runoff_aggregate_yyyymm$time_aggregate,  
                     labels = abbreviate) +
    facet_wrap( ~ basin,ncol = 1) +
    theme_minimal() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

# Code
This section defines the code for the `aggregate_time` function. 
The time aggregation is done by cutting the needed information out of the 
date-string. This is a rough, but works nicely and seems to be more 
commonly used than you would expect. 
```{r}
  #' Time Aggregation
  #' 
  #' Aggregates the cosero data.frame (\code{cos_data}) according to the 
  #' timely resolution defined via \code{aggregation}. Possible 
  #' resolution-choices are \code{'yyyy'} - year, \code{'mm'} - month and
  #' \code{'dd}' - day and combinations thereof. 
  #' 
  #' @param cos_data the COSERO data.frame as used within visCOS
  #' @param aggregation string that defines the resolution of the aggregation.
  #' @import magrittr
  #' @import ggplot2
  #' @import pasta
  #' @export
  aggregate_time <- function(cos_data, aggregation = "mm") {
    #
    cutting_bounds <- c(Inf,-Inf)
    if (grepl("dd",aggregation)) {
      cutting_bounds[1] <- min(9,cutting_bounds[1])
      cutting_bounds[2] <- max(11,cutting_bounds[2])
    }
    if (grepl("mm",aggregation)) {
      cutting_bounds[1] <- min(6,cutting_bounds[1])
      cutting_bounds[2] <- max(7,cutting_bounds[2])
    }
    if (grepl("yyyy",aggregation)) {
      cutting_bounds[1] <- min(1,cutting_bounds[1])
      cutting_bounds[2] <- max(4,cutting_bounds[2])
    }
```

```{r}
    ###### function and string definitions
    regex_for_cos_selection <- viscos_options("name_o") %|%  viscos_options("name_s")
    # aggregation function:
    aggregator_fun <- function(k,data_frame){
      the_aggregation <- aggregate(data_frame[[k]] ~ data_frame$date_selection, FUN = mean)
      return(the_aggregation[ ,2])
    }
    ##### 
    # If cos_data is not provided fully, the date is completed automatically 
    # + junk is removed from the data frame
    full_cos_data <- cos_data %>% 
      visCOS::prepare_complete_date() %>% 
      visCOS::remove_junk() 
    # aggregate:
    cos_with_aggreggation <- cbind.data.frame(
      full_cos_data,
      date_selection = substr(full_cos_data$posixdate,
                              cutting_bounds[1],
                              cutting_bounds[2]) %>% as.factor()
      )
    names_cos_selection <- grep(
      regex_for_cos_selection,
      names(cos_with_aggreggation) %>% tolower, 
      value = TRUE
      )
    selected_cos_rows <- grep(regex_for_cos_selection,
                             names(cos_with_aggreggation), 
                             ignore.case = TRUE)
    time_aggregate <- selected_cos_rows %>% 
      sapply(.,function(x) aggregator_fun(x,cos_with_aggreggation)) %>% 
      data.frame(idx = 1:nrow(.), 
                 time_aggregate = unique(cos_with_aggreggation$date_selection),
                 .) %>% 
      set_names(., c("idx","time_aggregate",names_cos_selection)) 
    # melt the data in a tidy format:
    melted_time_aggregate <- time_aggregate %>% 
      reshape2::melt(., id.vars = c("idx","time_aggregate")) %>% 
      cbind.data.frame(., 
                       basin =  .$variable %>%
                         gsub(regex_for_cos_selection,"",.) %>% 
                         gsub("\\D","",.) %>%
                         as.integer, 
                       obs_sim = .$variable %>% 
                         gsub(viscos_options("name_o") %&% ".*",viscos_options("name_o"),.) %>% 
                         gsub(viscos_options("name_s") %&% ".*",viscos_options("name_s"),.))
    return(melted_time_aggregate)
  }
```




<!--chapter:end:LP-time_aggregation.Rmd-->

---
title: "visCOS - Options"
author: 
- "Daniel Klotz, Johannes Wesemann, Mathew Herrnegger"
date: "11 Juli 2016"
output: 
  html_document:
    number_sections: yes
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(eval = FALSE, tidy = FALSE)
```

# Introduction 
This section defines code of the visCOS functions used to set and adapt the 
visCOS options. With the added comments code is pretty much self-explanatory. 

```{r}
#' visCOS global options
#' 
#' Get and set the global options of visCOS
#' 
#' These are the options you can adapt by executing the function 
#' (default values)
#' \preformatted{
#'   viscos_options(
#'    # data.frame column names
#'       name_o = "qobs", # name of the first time-series data (observations)  
#'       name_s = "qsim", # name of the second time-series data (simulations)  
#'       name_COSyear = "yyyy", # name of year-column
#'       name_COSmonth = "mm",  # name of month-column
#'       name_COSday = "dd",  # name of day-column
#'       name_COShour = "hh", # name of hour-column
#'       name_COSmin = "min", # name of minute-column
#'       name_COSposix = "posixdate", # name of the complete-date-column
#'       name_COSperiod = "period", # name of the marked-period column
#'    # plot options
#'       color_o = "steelblue", # color associated with the first o time-series data
#'       color_s= "orange",  # color associated with the second s time-series data
#'       legend_title = "legend", 
#'       xlab = "year",
#'       midpoint = 0.5,
#'       of_limits = c(0,1)
#'   )
#' }
#'
#' @examples
#' viscos_options("name_o")
#' viscos_options(name_o = "OtherData")
#' viscos_options("name_o")
#' @export
viscos_options <- GlobalOptions::setGlobalOptions( 
  # data.frame column names
  name_o = "qobs", 
  name_s = "qsim", 
  name_COSyear = "yyyy",
  name_COSmonth = "mm",
  name_COSday = "dd",
  name_COShour = "hh",
  name_COSmin = "min",
  name_COSposix = "posixdate",
  name_COSperiod = "period",
 # plot options
  color_o = "steelblue", 
  color_s = "orange",
  midpoint = 0.5,
  of_limits = c(0,1)
)

```


<!--chapter:end:LP-viscos_options.Rmd-->

